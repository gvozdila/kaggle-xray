{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# with open('alexnet.fea', 'rb') as f:\n",
    "#     alex_features = pickle.load(f)\n",
    "        \n",
    "\n",
    "alex_features = np.array(joblib.load('alexnet.fea'))\n",
    "alex_labels = np.array(joblib.load('alexnet.labels'))\n",
    "\n",
    "train_metadata_df = pd.read_csv('dicom_metadata_train_merged.csv') # Took it from kaggle notebooks\n",
    "import torch\n",
    "\n",
    "#alex_np_fea = [ elem[0] for elem in alex_features ]\n",
    " \n",
    "\n",
    "mult_lab = train_metadata_df.iloc[:, 64:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#from torchvision.io import read_image toooo old fot that stuff\n",
    "\n",
    "\n",
    "\n",
    "class featuresDataset(Dataset):\n",
    "    def __init__(self,  features_list, labels = None, merged_df = None, transform = None, target_transform = None):\n",
    "        if not merged_df:\n",
    "            self.img_labels = labels\n",
    "            self.use_labels = True\n",
    "        else:\n",
    "            self.img_labels = merged_df\n",
    "        self.features_list = features_list\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        print(\"Dataset loaded. Length = \",len(self.features_list))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features_list[idx]\n",
    "        if self.use_labels:\n",
    "            label = self.img_labels[idx]\n",
    "        else:\n",
    "            label = self.img_labels.iloc[idx, 64:]\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return feature, label\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.features_list , self.img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "\n",
    "training_data = featuresDataset(\n",
    "#    merged_df=train_metadata_df,\n",
    "    labels = alex_labels,\n",
    "    features_list=alex_features,\n",
    "#    train=True,\n",
    "#    download=True,\n",
    "    #transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type(training_data.get_all_data()[0][0].shape),training_data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.1 * len(training_data))\n",
    "test_size = len(training_data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(training_data, [train_size, test_size])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(alex_features, alex_labels, test_size=0.90, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example cant work with multi-lable.\n",
    "# Need to find other solution\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif,chi2\n",
    "\n",
    "import heapq\n",
    "\n",
    "selected_features_indexes = set()\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "def select_features(X_train, y_train, X_test,i,selected_features_indexes):\n",
    "    # configure to select all features\n",
    "    #fs = SelectKBest(score_func=f_classif, k=i)\n",
    "    for label_num in range(len(y_train[0])):\n",
    "        gc.collect()\n",
    "        fs = SelectKBest(score_func=f_classif, k='all')\n",
    "        # learn relationship from training data\n",
    "        fs.fit(X_train, y_train[:,label_num])\n",
    "        # transform train input data\n",
    "        X_train_fs = fs.transform(X_train)\n",
    "        # transform test input data\n",
    "        X_test_fs = fs.transform(X_test)\n",
    "        weights_for_label = fs.scores_\n",
    "        #print(fs.scores_, fs.scores_.shape)\n",
    "        selected_features_indxs = heapq.nlargest(i, range(len(weights_for_label)), weights_for_label.take)\n",
    "        #print(set(selected_features_indxs))\n",
    "        selected_features_indexes = selected_features_indexes.union(set(selected_features_indxs))\n",
    "    return X_train_fs, X_test_fs , selected_features_indexes\n",
    "\n",
    "\n",
    "fs_X_train,fs_X_test,selected_features_indexes = select_features(X_train, y_train, X_test, 20 ,selected_features_indexes)\n",
    "\n",
    "print(len(selected_features_indexes),selected_features_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "threshold = 200.5\n",
    "\n",
    "\n",
    "selected_features = [] \n",
    "for label_num in range(y_train.shape[1]):\n",
    "    selector = SelectKBest(f_classif, k='all')\n",
    "    selector.fit(X_train, y_train[:,label_num])\n",
    "    selected_features.append(list(selector.scores_))\n",
    "\n",
    "#/ / MeanCS \n",
    "#selected_features = np.mean(selected_features, axis=0) > threshold\n",
    "#// MaxCS\n",
    "#selected_features = np.max(selected_features, axis=0) > threshold\n",
    "\n",
    "# Этот вариант работает с multi-label. Но тут есть тонкость.\n",
    "# Нужно отобрать features так, чтоб для каждого класса самые информативные присутствовали. \n",
    "# А мне кажется, что присутствуют те, в которых большая информативность хотя бы для одного класса.\n",
    "# И возможна ситуация, что найдется класс, для которого не отобрались хоть сколько-то информативные фичи.\n",
    "\n",
    "#len(selected_features[0])\n",
    "# selected_features\n",
    "# len(X_train[0][selected_features])\n",
    "\n",
    "selected_features = heapq.nlargest(176, range(len(selected_features)), selected_features.__getitem__)\n",
    "selected_features # i have no idea what happends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VarianceThreshold is a simple baseline approach to feature selection. \n",
    "# It removes all features whose variance doesn’t meet some threshold\n",
    "\n",
    "# Can we use it?\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tr = np.arange(0.0, 1.0, 0.01)\n",
    "s=[]\n",
    "for ttt in tr:\n",
    "    selector = VarianceThreshold(threshold=ttt)\n",
    "    selector.fit_transform(X_train).shape\n",
    "    \n",
    "    s.append(selector.transform(X_test[0:1]).shape[1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tr, s)\n",
    "\n",
    "ax.set(xlabel='Threshold', ylabel='Feature remains',\n",
    "       title='About as simple as it gets, folks')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(X_train[0].shape[0])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation_importance \n",
    "# Permutation feature importance is a model inspection technique that\n",
    "#  can be used for any fitted estimator when the data is tabular.\n",
    "# This is especially useful for non-linear or opaque estimators. \n",
    "# The permutation feature importance is defined to be the decrease\n",
    "#  in a model score when a single feature value is randomly shuffled 1. \n",
    "# This procedure breaks the relationship between the feature and the target,\n",
    "#  thus the drop in the model score is indicative of how much the model depends\n",
    "#  on the feature. This technique benefits from being model agnostic and\n",
    "#  can be calculated many times with different permutations of the feature.\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "wanna_permutation_picture = False\n",
    "if wanna_permutation_picture:\n",
    "    start_time = time.time()\n",
    "    result = permutation_importance(\n",
    "        forest, X_test, y_test, n_repeats=2, random_state=42, n_jobs=4\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "    forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wanna_permutation_picture:\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model\")\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "len(X_train), X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "import datetime\n",
    "#rfc = RandomForestClassifier(n_jobs=7, n_estimators= 100)\n",
    "#rfc.fit(X_train,y_train)\n",
    "# (rfc.predict(X_train) - y_train).mean()\n",
    "# (rfc.predict(X_test) - y_test).mean()\n",
    "\n",
    "# Here we will test importance of  n_estimators&max_depth \n",
    "# Note, that X_train is only 0.1 of total TRAIN data set. So real fit will takes 10 times longer\n",
    "for n_trees in [100 * i*i +1 for i in range(35)]:\n",
    "    for depth in [i * i*i*i for i in range(4)]:\n",
    "        time_start = datetime.datetime.now()\n",
    "        if depth < 1:\n",
    "            rfc = RandomForestClassifier(n_jobs=7, n_estimators= n_trees)\n",
    "        else:\n",
    "            rfc = RandomForestClassifier(n_jobs=7,max_depth = depth, n_estimators= n_trees)\n",
    "        rfc.fit(X_train,y_train)\n",
    "        pred = rfc.predict(X_test)\n",
    "\n",
    "        print(f\"For {n_trees} trees with depth {depth} RFC hamming loss = {hamming_loss(pred,y_test)} it takes {datetime.datetime.now() -time_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pred = clf.predict(X_test)\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "hamming_loss(clf_pred,y_test), hamming_loss(rfc_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(n_jobs=7, n_estimators= 100)\n",
    "rfc2.fit(X_train,y_train)\n",
    "rfc2_pred = rfc2.predict(X_test)\n",
    "hamming_loss(rfc2_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2.fit(X_train,y_train)\n",
    "rfc2_pred = rfc2.predict(X_test)\n",
    "hamming_loss(rfc2_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = None # Find index of predictions with different results\n",
    "for i in range(len(rfc2_pred)):\n",
    "    if (rfc2_pred[i] != clf_pred[i]).any():\n",
    "        di = i\n",
    "        break\n",
    "\n",
    "double_lable = None # Trying to find index of prediction with double lable\n",
    "for i in range(len(rfc2_pred)):\n",
    "    if (sum(rfc2_pred[i])>1):\n",
    "        double_lable = i\n",
    "        break\n",
    "\n",
    "rfc_l = hamming_loss(rfc_pred,y_test)\n",
    "clf_l = hamming_loss(clf_pred,y_test)\n",
    "rfc2_l = hamming_loss(rfc2_pred,y_test)\n",
    "\n",
    "rfc2_pred[di],clf_pred[di],di,len(rfc2_pred),rfc2_pred.shape,[rfc2_l,clf_l,rfc_l],'double label example = ', rfc2_pred[double_lable]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create function for vote for predictions\n",
    "def prediction_voting(predicts, voters_loss = None, voters_quality = None):\n",
    "    if voters_loss:\n",
    "        voters_quality = [ 1 / ll for ll in voters_loss]\n",
    "    if not voters_quality:\n",
    "        print(\"Need voters_loss or voters_quality\")\n",
    "        return\n",
    "    pred_count = len(predicts)\n",
    "    samples_count = len(predicts[0])\n",
    "    labels_count = len(predicts[0][0])\n",
    "    best_num = voters_quality.index(max(voters_quality)) # number of best predictor\n",
    "    final_predicts = []\n",
    "    for sample_num in range(samples_count ):\n",
    "        s_preds = [predict[sample_num] for predict in predicts]\n",
    "        pro = np.zeros(shape=(labels_count))\n",
    "        cons = np.zeros(shape=(labels_count))\n",
    "        res = np.zeros(shape=(labels_count))\n",
    "        print(\"predicts \",s_preds)\n",
    "        for pred_num in range(len(s_preds)):\n",
    "            pred = s_preds[pred_num]\n",
    "            qa = voters_quality[pred_num]\n",
    "            pro = (pred == 1)*qa\n",
    "            cons = -1 * (pred == 0)*qa\n",
    "            \n",
    "            res +=  pro + cons\n",
    "            res2 = np.where(res < 0, 0, 1)\n",
    "            #print(\"pros\",pro,\"\\ncons \",cons, \"\\nsumm \", res,\"\\nresults \", res2)\n",
    "        print(\"\\nsumm \", res,\"\\nresults \", res2)\n",
    "        \n",
    "        if sum(res2) < 0.5:\n",
    "            res2 = s_preds[best_num]\n",
    "        final_predicts.append(res2)\n",
    "    return final_predicts\n",
    "\n",
    "    \n",
    "\n",
    "vote_pred = prediction_voting([rfc2_pred,clf_pred,rfc_pred],[rfc2_l,clf_l,rfc_l])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing predictions before vote and after\n",
    "[rfc2_l,clf_l,rfc_l], hamming_loss(vote_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check RandomForestClassifier criterion. Is it worth it to choose and change default.\n",
    "for cla in [\"gini\",\"entropy\",\"log_loss\"]:\n",
    "    test_rfc = RandomForestClassifier(n_jobs=7, n_estimators= 1000,criterion=cla)\n",
    "    test_rfc.fit(X_train,y_train)\n",
    "    test_rfc_pred = rfc.predict(X_test)\n",
    "    print(cla,\" \",hamming_loss(test_rfc_pred,y_test))\n",
    "# Looks like very close results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2string(labels): # little magic to convert array like [0,1,1,0,0,1] to string like '1 2 5'\n",
    "    return \" \".join([ str(aa[0]) for aa in  np.argwhere(labels>0) ])\n",
    "\n",
    "\n",
    "ppp = vote_pred[double_lable]\n",
    "labels2string(ppp) # And simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i just want to test models and, may be, Tree_classifiers\n",
    "#from sklearn.ensemble import RandomForest, ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from torchvision import models\n",
    "import gc # garbage collector, can help you free memory\n",
    "\n",
    "\n",
    "model_names = [\"resnet50\", \n",
    "\"densenet161\", \n",
    "\"wide_resnet50_2\",\n",
    "\"vgg13\"]\n",
    "\n",
    "trees_ensembles = { \"RandomForest\":RandomForestClassifier(n_jobs=7, n_estimators= 10000),\n",
    "\"ExtraTrees\":ExtraTreesClassifier(n_jobs=7, n_estimators= 10000)}\n",
    "mult_lab = train_metadata_df.iloc[:, 64:]\n",
    "\n",
    "magic_test_results=dict()\n",
    "for model_name in model_names:\n",
    "    gc.collect()\n",
    "    with open(model_name+'.fea', 'rb') as f:\n",
    "        model_fea = pickle.load(f)\n",
    "\n",
    "    train_metadata_df = pd.read_csv('dicom_metadata_train_merged.csv') # Took it from kaggle notebooks\n",
    "    import torch\n",
    "    model_magic_result = dict()\n",
    "    model_fea = [ elem.numpy()[0] for elem in model_fea ]\n",
    "    X_m_train, X_m_test, y_m_train, y_m_test = train_test_split(model_fea, mult_lab, test_size=0.33, random_state=42)\n",
    "    gc.collect()\n",
    "    for tree_name in trees_ensembles.keys():\n",
    "        gc.collect()\n",
    "        tree = trees_ensembles[tree_name]\n",
    "        tree.fit(X_m_train,y_m_train)\n",
    "        tree_pred = tree.predict(X_m_test)\n",
    "        model_magic_result[tree_name] = hamming_loss(tree_pred,y_m_test)\n",
    "\n",
    "    magic_test_results[model_name] = model_magic_result\n",
    "    del model_fea\n",
    "    del tree\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_epoch = magic_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe26e90ddbd5367fa5ee0049ef632efa5773b42c0e43943819d0e30fa09b08ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
