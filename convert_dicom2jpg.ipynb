{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1652001172985,
     "user": {
      "displayName": "Полиграф Полиграфыч",
      "userId": "02946022291237464115"
     },
     "user_tz": -180
    },
    "id": "GLHABMbKUxUc"
   },
   "outputs": [],
   "source": [
    "import pydicom # библиотека для работы с DICOM файлами\n",
    "\n",
    "from matplotlib import cm # цветовые схемы для визуализации\n",
    "from matplotlib import pyplot as plt # библиотека для визуализации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "pool = mp.Pool(mp.cpu_count()-4)\n",
    "import pydicom # библиотека для работы с DICOM файлами\n",
    "\n",
    "from matplotlib import cm # цветовые схемы для визуализации\n",
    "from matplotlib import pyplot as plt # библиотека для визуализации \n",
    "\n",
    "import glob\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "\n",
    "from os.path import basename, dirname, splitext\n",
    "!cd /home/krom/projects/ML\n",
    "files_path = glob.glob(\"./**/*.dcm\",recursive=True)\n",
    "files_path\n",
    "fff= files_path\n",
    "fff\n",
    "def dcm2jpg(files):\n",
    "    #print(\"files\", files, \"\\n\" , len(files))\n",
    "    #for dcm_name in files:\n",
    "    # cv.COLORMAP_HSV\n",
    "    if 1==1:\n",
    "        dcm_name=files\n",
    "        imagedata = pydicom.dcmread(dcm_name)\n",
    "        img = imagedata.pixel_array\n",
    "        #print(dcm_name + \"\\n\")\n",
    "        clean_name, exten = splitext(dcm_name)\n",
    "        p_dir = dirname(dcm_name)\n",
    "        f_name = basename(dcm_name)\n",
    "        png_name = '{}.png'.format(clean_name)\n",
    "        jpg_name = '{}.jpg'.format(clean_name)\n",
    "        img = skimage.exposure.equalize_adapthist(img)\n",
    "        #imC = cv2.applyColorMap(im, cv2.COLORMAP_JET)\n",
    "        #cv2.imwrite(png_name, cv2.applyColorMap(img, cv2.COLORMAP_JET)  )\n",
    "        !echo $png_name\n",
    "        \n",
    "        #plt.imsave(png_name,img,cmap=plt.cm.hsv)\n",
    "        #!convert $png_name -resize 512x512 -gravity center -background black -extent 512x512 $jpg_name \n",
    "        #!rm -f $png_name\n",
    "        plt.imsave(png_name,img,cmap=plt.cm.bone)\n",
    "        jpg_name = '{}.bone.jpg'.format(clean_name)\n",
    "        !convert $png_name -resize 512x512 -gravity center -background black -extent 512x512 $jpg_name \n",
    "        !rm -f $png_name $dcm_name\n",
    "        \n",
    "    return files\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedata = pydicom.dcmread(files_path[733])\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "img = imagedata.pixel_array\n",
    "img = skimage.exposure.equalize_adapthist(img)\n",
    "\n",
    "ax.imshow(imagedata.pixel_array, cmap=plt.cm.bone)\n",
    "ax2.imshow(img, cmap=plt.cm.hsv)  \n",
    "plt.imsave(\"lot.png\",imagedata.pixel_array,cmap=plt.cm.hsv)\n",
    "plt.imsave(\"cot.png\",img,cmap=plt.cm.hsv)\n",
    "plt.imsave(\"bot.png\",img,cmap=plt.cm.bone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "%time results = pool.map(dcm2jpg, fff)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2jpg(fff):\n",
    "    for f_f in fff:\n",
    "        dcm2jpg(f_f)\n",
    "        \n",
    "%time seq2jpg(fff)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvYnS5Jck7Cj"
   },
   "source": [
    "# Такой вариант работает, но не учитывает метаданные, которые относятся к изображению. В основном это касается BitsAllocated и PhotometricInterpretation\n",
    "\n",
    "Значение Photometric Interpretation определяет предполагаемую интерпретацию данных пикселей изображения.\n",
    "\n",
    "Нас тут интересуют основные два значения для рентгена:\n",
    "\n",
    "MONOCHROME1 - Пиксельные данные представляют собой одну плоскость монохромного изображения. Минимальное значение выборки предназначено для отображения белым цветом после выполнения любых преобразований шкалы серого VOI.\n",
    "MONOCHROME2 - Пиксельные данные представляют собой одну плоскость монохромного изображения. Минимальное значение выборки предназначено для отображения черным цветом после выполнения любых преобразований шкалы серого VOI.\n",
    "Bits Allocated - Количество бит, выделенных для каждой выборки пикселей. Каждой выборке должно быть выделено одинаковое количество битов. Выделенные биты должны быть либо 1, либо кратными 8.\n",
    "\n",
    "Проверим метатеги у нашего примера и попробуем конвертировать изображение.\n",
    "\n",
    "print(imagedata.BitsAllocated)\n",
    "print(imagedata.PhotometricInterpretation)\n",
    "На нашем примере мы увидим 8 и MONOCHROME2. Код переделывать не придётся. Но в случае если PhotometricInterpretation было бы MONOCHROME1 изображение получилось бы инвертированным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1652002219022,
     "user": {
      "displayName": "Полиграф Полиграфыч",
      "userId": "02946022291237464115"
     },
     "user_tz": -180
    },
    "id": "l-7H2Qdhk-ZB",
    "outputId": "4ac897dc-be74-482b-a190-93320c0bc082"
   },
   "outputs": [],
   "source": [
    "print(imagedata.BitsAllocated)\n",
    "print(imagedata.PhotometricInterpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHOFxNFolcZS"
   },
   "source": [
    "img = np.invert(imagedata.pixel_array)\n",
    "\n",
    "В случае если PhotometricInterpretation было бы MONOCHROME1 изображение получилось бы инвертированным. Поэтому используем np.invert, что бы минимальное значение выборки было отображением черного цвета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvBqymw4pBtN"
   },
   "source": [
    "Сегментация изображения — это разделение изображения на несколько сегментов (множество пикселей). Сегментация изображений обычно используется для того, чтобы выделить объекты и границы на изображениях. Более точно, сегментация изображений — это процесс присвоения таких меток каждому пикселю изображения, что пиксели с одинаковыми метками имеют общие визуальные характеристики.\n",
    "\n",
    "Сегментация применяется во многих областях, например, в производстве для индикации дефектов при сборке деталей, в медицине для поиска опухолей и других патологий, также для составления карт местности по снимкам со спутников итд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 2818,
     "status": "ok",
     "timestamp": 1652002236953,
     "user": {
      "displayName": "Полиграф Полиграфыч",
      "userId": "02946022291237464115"
     },
     "user_tz": -180
    },
    "id": "kEHtNwhJplCY",
    "outputId": "858b4f4f-c8ea-498c-8ead-a6dd84c5a248"
   },
   "outputs": [],
   "source": [
    "#Рассмотрим алгоритм сегментации на основе графов Felsenszwalb из библиотеки skimage. \n",
    "#Алгоритм производит сегментацию многоканального (например, RGB) изображения с использованием быстрой кластеризации\n",
    "# на основе минимального связующего дерева на сетке изображения. \n",
    "#Параметр scale задает уровень наблюдения. Чем выше scale, тем меньше сегментов и они большего размера.\n",
    "# sigma - это диаметр гауссова ядра, используемого для сглаживания изображения перед сегментацией.\n",
    "#Количество производимых сегментов, а также их размер можно контролировать только косвенно через scale.\n",
    "# Размер сегмента в изображении может сильно различаться в зависимости от контраста. \n",
    "#Для изображений RGB алгоритм использует евклидово расстояние между пикселями в цветовом пространстве.\n",
    "\n",
    "#Нашей задачей будет в уже знакомом  рентген снимке попробовать сегментировать оба легких.\n",
    "\n",
    "example = 'drive/MyDrive/siim-acr-pneumothorax-segmentation/stage_2_images/ID_240440107.dcm'\n",
    "imagedata= pydicom.dcmread(example)\n",
    "\n",
    "# Импортируем нужные библиотеки\n",
    "import numpy as np\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.transform import rescale\n",
    "\n",
    "#Занулим значения больше 65\n",
    "\n",
    "im_thres = imagedata.pixel_array.copy()\n",
    "im_thres[im_thres > 65] = 0\n",
    "\n",
    "\n",
    "#Масштабируем и фильтруем и нормализовываем картинку\n",
    "\n",
    "im_small = rescale(im_thres, 0.65)\n",
    "im_small_filt = median(im_small, disk(50))   \n",
    "im_small_filt = equalize_hist(im_small_filt)\n",
    "#Запускаем сам алгоритм\n",
    "\n",
    "segments = felzenszwalb(im_small_filt, scale=0.5)\n",
    "#Визуализируем и посмотрим, что получилось\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "ax.imshow(imagedata.pixel_array, cmap=plt.cm.bone)\n",
    "ax2.imshow(segments, cmap=plt.cm.bone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG73aziWtwWE"
   },
   "source": [
    "Надо попробовать поиграть с параметрами, пока получается довольно-таки хреново.Лучше всего с сегментацией справляются нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDAmS-D7ueSy"
   },
   "source": [
    "Для начала рассмотрим библиотеку lungs-segmentation. Она как раз решает задачу сегментации правого и левого лёгкого.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2798,
     "status": "ok",
     "timestamp": 1652002251448,
     "user": {
      "displayName": "Полиграф Полиграфыч",
      "userId": "02946022291237464115"
     },
     "user_tz": -180
    },
    "id": "5XOgWKhIutMj",
    "outputId": "2765c089-a3ee-4e32-b071-43b251b9bd48"
   },
   "outputs": [],
   "source": [
    "pip install lungs-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "executionInfo": {
     "elapsed": 4709,
     "status": "ok",
     "timestamp": 1652002964364,
     "user": {
      "displayName": "Полиграф Полиграфыч",
      "userId": "02946022291237464115"
     },
     "user_tz": -180
    },
    "id": "db9Rs9zavP4a",
    "outputId": "07766419-7e6c-4751-b657-7d915426eada"
   },
   "outputs": [],
   "source": [
    "#Библиотека работает с PNG изображениями, поэтому сначала сконвертируем изображение уже знакомым нам способом.\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "\n",
    "example = 'drive/MyDrive/siim-acr-pneumothorax-segmentation/stage_2_images/ID_240440107.dcm'\n",
    "imagedata= pydicom.dcmread(example)\n",
    "\n",
    "img =imagedata.pixel_array\n",
    "name = example.split('/')[-1][:-4]\n",
    "img = resize(img,(512,512))\n",
    "cv2.imwrite('{}.png'.format(name), img * 255)\n",
    "\n",
    "#После чего импортируем lungs-segmentation и запускаем обработку моделью\n",
    "\n",
    "from lungs_segmentation.pre_trained_models import create_model\n",
    "import lungs_segmentation.inference as inference\n",
    "import torch\n",
    "\n",
    "model = create_model(\"resnet34\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1,1,1)\n",
    "image, mask = inference.inference(model,'ID_240440107.png', 0.2)\n",
    "plt.imshow(inference.img_with_masks( image, [mask[0], mask[1]], alpha = 0.1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNrLqwh6L5G4dWNZqMA8fhu",
   "collapsed_sections": [],
   "name": "pneumotorax.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
